{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialization 1214\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import constrNMPy\n",
    "import os \n",
    "import warnings\n",
    "\n",
    "from matplotlib import gridspec\n",
    "from scipy import sparse, special, stats\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "# color pallette\n",
    "[gr,ye,re,bl,pu,ir,ak] = ['#8ECFC9', '#FFBE7A', '#FA7F6F', '#82B0D2','#BEB8DC', '#E7DAD2','#999999']\n",
    "[vio, grb, lig, sil, aqua] = ['#8c84cf','#6699CC','#66CC99','#C0C0C0','#6db3bc']\n",
    "# set the style of the plots\n",
    "az.style.use(\"arviz-white\")\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'Arial'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fictive Learning for Reinforcement Learning\n",
    "\n",
    "根据前面的几个单纯强化学习模型的尝试，我们可以发现，不仅知觉上的吸引效应没有办法被重复（我们固定了criterion），在按键上的排斥效应在理论上来讲也基本无法看见：在控制总体的正确率较高的情况下，对于所有按键的平均，肯定是整体呈现出价值积累的趋势，即平均的价值变化都是正向的，出现按键上的吸引模式。\n",
    "\n",
    "采用fictive learning的方法，我们可以在理论上解决这个问题。我们可以假设，在价值更新的过程中，不仅仅是选择了的按键的价值会被更新，而是所有按键的价值都会被更新，只不过选择的按键的价值会被更新的更多一些。这样，我们就可以在理论上解决按键上的排斥效应的问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
